{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: predict whether a loan will end up with maximum profits or not\n",
    "\n",
    "---\n",
    "#### Target variable: `zeroBalCode` \n",
    "* Type: **Categorical** \n",
    "* Model type: Classification \n",
    "* Sourced from: `zeroBalCode`\n",
    "* Data: \n",
    "    - \"0\" means \"Successful outcome for Fannie Mae\"\n",
    "    - \"1\" means \"Negative outcome for Fannie Mae\"\n",
    "    \n",
    "#### This Notebook:\n",
    "* Input required: The output .pkl model file from \"Scott - Model - 1- PyCaret Setup and Create Model\" notebook\n",
    "* Outputs generated: None\n",
    "\n",
    "#### Expected Workflow\n",
    "1. Scott - Data Pre - 1 - Feature EEE\n",
    "2. Scott - Data Pre - 2 - 50 50 split train test\n",
    "3. Scott - Model - 1- PyCaret Setup and Create Model\n",
    "4. Scott - Predict - 1 - Holdout Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import winsound\n",
    "\n",
    "# Tell Jupyter to display all text, not just \"the last\" and print()\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "%pwd\n",
    "\n",
    "def DoneNotice(duration_ms = 1000):\n",
    "    duration = duration_ms  # milliseconds\n",
    "    freq = 440  #Hz\n",
    "    winsound.Beep(freq, duration)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def Important(html_tag, message, color):\n",
    "    colorstr = f\"<{html_tag} style='color:{color}'>{message}</{html_tag}>\"\n",
    "    display(Markdown(colorstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .pkl will be automatically added by PyCaret\n",
    "model = '../models/et20200526_2010'\n",
    "\n",
    "# What is the model's target variable?\n",
    "target = 'zeroBalCode'\n",
    "\n",
    "# What are the inputs to the model?\n",
    "predictors = [\n",
    "    'origChannel'\n",
    "    , 'loanPurp'\n",
    "    , 'bankNumber'\n",
    "    , 'stateNumber'\n",
    "    , 'mSA'\n",
    "    , 'origIntRate'\n",
    "    , 'origUPB'\n",
    "    , 'origLTV'\n",
    "    , 'numBorrowers'\n",
    "    , 'origDebtIncRatio'\n",
    "    , 'worstCreditScore'\n",
    "]\n",
    "\n",
    "# Where is your holdout data?\n",
    "holdoutData = '../data/DataPre-01-Feature-EEE-2012.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Sucessfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .boolean { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .integer { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .string  { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=['origChannel',\n",
      "                                                            'loanPurp',\n",
      "                                                            'bankNumber',\n",
      "                                                            'stateNumber',\n",
      "                                                            'mSA'],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=['origIntRate',\n",
      "                                                          'origUPB', 'origLTV',\n",
      "                                                          'numBorrowers',\n",
      "                                                          'origDebtIncRatio',\n",
      "                                                          'worstCreditScore'],\n",
      "                                      target='zeroBalCode', time_features=...\n",
      "                                                  target='zeroBalCode')),\n",
      "                ('P_transform', Empty()), ('pt_target', Empty()),\n",
      "                ('binn', Empty()), ('rem_outliers', Empty()),\n",
      "                ('cluster_all', Empty()),\n",
      "                ('dummy', Dummify(target='zeroBalCode')),\n",
      "                ('fix_perfect', Remove_100(target='zeroBalCode')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', Empty()), ('fix_multi', Empty()),\n",
      "                ('dfs', Empty()), ('pca', Empty())],\n",
      "         verbose=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=5467, verbose=0,\n",
      "                     warm_start=False)]\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from pycaret.classification import *\n",
    "the_model = load_model(model)\n",
    "\n",
    "DoneNotice(2000)\n",
    "\n",
    "print(the_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in holdout data (2011 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>origChannel</th>\n",
       "      <th>origIntRate</th>\n",
       "      <th>origUPB</th>\n",
       "      <th>origLTV</th>\n",
       "      <th>numBorrowers</th>\n",
       "      <th>origDebtIncRatio</th>\n",
       "      <th>loanPurp</th>\n",
       "      <th>worstCreditScore</th>\n",
       "      <th>bankNumber</th>\n",
       "      <th>stateNumber</th>\n",
       "      <th>mSA</th>\n",
       "      <th>zeroBalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92143</td>\n",
       "      <td>3</td>\n",
       "      <td>5.250</td>\n",
       "      <td>46000</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>691</td>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>44180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92144</td>\n",
       "      <td>1</td>\n",
       "      <td>4.375</td>\n",
       "      <td>219000</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>752</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>35620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92145</td>\n",
       "      <td>3</td>\n",
       "      <td>4.875</td>\n",
       "      <td>76000</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>692</td>\n",
       "      <td>29</td>\n",
       "      <td>44</td>\n",
       "      <td>16860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92147</td>\n",
       "      <td>1</td>\n",
       "      <td>4.250</td>\n",
       "      <td>101000</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>686</td>\n",
       "      <td>54</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92148</td>\n",
       "      <td>1</td>\n",
       "      <td>4.375</td>\n",
       "      <td>256000</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>723</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>35380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  origChannel  origIntRate  origUPB  origLTV  numBorrowers  \\\n",
       "0       92143            3        5.250    46000       80             2   \n",
       "1       92144            1        4.375   219000       70             2   \n",
       "2       92145            3        4.875    76000       78             1   \n",
       "3       92147            1        4.250   101000       75             1   \n",
       "4       92148            1        4.375   256000       80             1   \n",
       "\n",
       "   origDebtIncRatio  loanPurp  worstCreditScore  bankNumber  stateNumber  \\\n",
       "0                25         1               691          80           25   \n",
       "1                44         1               752          80           32   \n",
       "2                38         1               692          29           44   \n",
       "3                41         1               686          54           36   \n",
       "4                37         1               723          45           19   \n",
       "\n",
       "     mSA  zeroBalCode  \n",
       "0  44180            0  \n",
       "1  35620            1  \n",
       "2  16860            1  \n",
       "3      0            0  \n",
       "4  35380            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dfHoldout = pd.read_csv(holdoutData)\n",
    "dfHoldout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the previous index column\n",
    "dfHoldout.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict!\n",
    "Notice the last two columns 'Label' and 'Score'. \n",
    "- Label is the prediction \n",
    "- Score is the probability of the prediction\n",
    "The predicted results are concatenated to the original dataset while all transformations including imputation of missing values (in this case None), categorical encoding, feature extraction etc. are performed automatically under the hood and you do not have to manage the pipeline manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "unseen_predictions = predict_model(model, data=dfHoldout)\n",
    "unseen_predictions.head()\n",
    "\n",
    "DoneNotice(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = unseen_predictions[[target,'Label','Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confusion(row):\n",
    "    if ((row[target] == 0) & (row['Label'] == 0)):\n",
    "        value = 'TrueNegative'\n",
    "    elif ((row[target] == 0) & (row['Label'] == 1)):\n",
    "        value = 'FalseNegative'\n",
    "    elif ((row[target] == 1) & (row['Label'] == 1)):\n",
    "        value = 'TruePositive'\n",
    "    elif ((row[target] == 1) & (row['Label'] == 0)):\n",
    "        value = 'FalsePositive'\n",
    "    else:\n",
    "        value = 'Undefined'\n",
    "    return value\n",
    "\n",
    "results['Confusion'] = results.apply(calc_confusion, axis=1)\n",
    "\n",
    "confusionMatrix = results.Confusion.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def makeCell(input, position):\n",
    "    actual = len(str(input))\n",
    "    if actual == 7: # 3 and 3\n",
    "        return_string = (\" \" * 3) + str(input) + (\" \" * 3)\n",
    "    elif actual == 6: # 3 and 4\n",
    "        return_string = (\" \" * 3) + str(input) + (\" \" * 4)\n",
    "    elif actual == 5: # 4 and 4\n",
    "        return_string = (\" \" * 4) + str(input) + (\" \" * 4)\n",
    "    elif actual == 4: # 4 and 5\n",
    "        if position == 'left':\n",
    "            return_string = (\" \" * 4) + str(input) + (\" \" * 5)\n",
    "        else:\n",
    "            return_string = (\" \" * 4) + str(input) + (\" \" * 6)\n",
    "    elif actual == 3: # 5 and 5\n",
    "        if position == 'left':\n",
    "            return_string = (\" \" * 5) + str(input) + (\" \" * 5)\n",
    "        else:\n",
    "            return_string = (\" \" * 5) + str(input) + (\" \" * 6)\n",
    "    elif actual == 2: # 5 and 6\n",
    "        if position == 'left':\n",
    "            return_string = (\" \" * 5) + str(input) + (\" \" * 6)\n",
    "        else:\n",
    "            return_string = (\" \" * 5) + str(input) + (\" \" * 7)\n",
    "    else: # 1: 6 and 6\n",
    "        if position == 'left':\n",
    "            return_string = (\" \" * 6) + str(input) + (\" \" * 6)\n",
    "        else:\n",
    "            return_string = (\" \" * 6) + str(input) + (\" \" * 7)\n",
    "\n",
    "    return return_string\n",
    "\n",
    "def make_confusion_matrix(tn, fp, fn, tp):\n",
    "    print(f'           +----------------------------+')\n",
    "    print(f'           |(TN)         |          (FP)|')\n",
    "    print(f'         0 |{makeCell(tn, \"left\")}|{makeCell(fp, \"right\")}|')\n",
    "    print(f'           |             |              |')\n",
    "    print(f' Actual    |-------------|--------------|')\n",
    "    print(f'           |             |              |')\n",
    "    print(f'         1 |{makeCell(fn, \"left\")}|{makeCell(tp, \"right\")}|')\n",
    "    print(f'           |(FN)         |          (TP)|')\n",
    "    print(f'           |_____________|______________|')\n",
    "    print(f'                  0              1       ')\n",
    "    print(f'                     Predicted           ')\n",
    "          \n",
    "def getAccuracy(tp, tn, fp, fn, decimals):\n",
    "    try:\n",
    "        recall_sensitivity = tp / float(tp + fn)\n",
    "    except:\n",
    "        recall_sensitivity = 0\n",
    "\n",
    "    try:\n",
    "        precision = tp / float(tp + fp)\n",
    "    except:\n",
    "        precision = 0\n",
    "\n",
    "    try:\n",
    "        fscore = 2 * (precision * recall_sensitivity / precision + recall_sensitivity)\n",
    "        # fscore = 2*precision*recall / (precision + recall)\n",
    "    except:\n",
    "        fscore = 0\n",
    "\n",
    "    try:\n",
    "        accuracy = (tp + tn) / float(tp + tn + fp + fn)\n",
    "    except:\n",
    "        accuracy = 0\n",
    "          \n",
    "    try:\n",
    "        specificity = tn / float(tn + fp)\n",
    "    except:\n",
    "        specificity = 0\n",
    "          \n",
    "    try:\n",
    "        balanced_accuracy = (recall_sensitivity + specificity) / float(2)\n",
    "    except:\n",
    "        balanced_accuracy = 0\n",
    "          \n",
    "    # Specificity\n",
    "    # Specificity is the correctly -ve labeled by the program to all who are healthy in reality.\n",
    "    # Specifity answers the following question: Of all the people who are healthy, how many of those did we correctly predict?    \n",
    "          \n",
    "    # Precision = Ability of the classifier not to label as positive a sample that is negative.\n",
    "          \n",
    "    # Recall = Sensitivity = Ability of the classifier to find all the positive samples.\n",
    "          \n",
    "    # Balanced Accuracy = (sensitivity + specificity) / 2\n",
    "          \n",
    "    # https://stats.stackexchange.com/questions/49579/balanced-accuracy-vs-f-1-score\n",
    "    # Both F1 and Balanced Accuracy both (to some extent) handle class imbalance. For binary classification, \n",
    "    #     depending of which of the two classes (N or P) outnumbers the other, each metric outperforms the other:\n",
    "    #     - If N > P, F1 is better\n",
    "    #     - If P > N, Balanced Accuracy is better\n",
    "    # Clearly, if you can label-switch, both the metrics can be used in any of the two imbalance cases above. \n",
    "    # If not, then depending on the imbalance in the training data, you can select the appropriate metric.\n",
    "    # \n",
    "    # Balanced Accuracy = arithmetic mean of Recall for Positive and Negative\n",
    "    # F1 = harmonic mean of Recall_P and Precision_P\n",
    "    # \n",
    "    # Balanced Accurancy = (Sensitivity + Specificity) / 2\n",
    "    # F1 = \n",
    "\n",
    "    # Sensitivity is Recall\n",
    "          \n",
    "    # Specificity is the false positive rate. Sensitivity answers the question: \n",
    "    #     “How many of the positive cases did I detect?” \n",
    "    #     Or to put it in a manufacturing setting: “How many (truly) defective products did I manage to recall?” \n",
    "\n",
    "    return round(accuracy, decimals) \\\n",
    "          , round(precision, decimals) \\\n",
    "          , round(recall_sensitivity, decimals) \\\n",
    "          , round(fscore, decimals) \\\n",
    "          , round(specificity, decimals) \\\n",
    "          , round(balanced_accuracy, decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +----------------------------+\n",
      "           |(TN)         |          (FP)|\n",
      "         0 |    13504    |    1000      |\n",
      "           |             |              |\n",
      " Actual    |-------------|--------------|\n",
      "           |             |              |\n",
      "         1 |     458     |     186      |\n",
      "           |(FN)         |          (TP)|\n",
      "           |_____________|______________|\n",
      "                  0              1       \n",
      "                     Predicted           \n"
     ]
    }
   ],
   "source": [
    "tn = confusionMatrix[\"TrueNegative\"]\n",
    "tp = confusionMatrix[\"TruePositive\"]\n",
    "fn = confusionMatrix[\"FalseNegative\"]\n",
    "fp = confusionMatrix[\"FalsePositive\"]\n",
    "\n",
    "make_confusion_matrix(\n",
    "    tp = tp\n",
    "    , tn = tn\n",
    "    , fp = fp\n",
    "    , fn = fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9037\n",
      "Precision: 0.1568\n",
      "Recall: 0.2888\n",
      "F1: 1.1553\n",
      "Specificity: 0.9311\n",
      "Balanced Accuracy: 0.6099\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall_sensitivity, fscore, specificity, balanced_accuracy = getAccuracy(\n",
    "      tp = tp\n",
    "    , tn = tn\n",
    "    , fp = fp\n",
    "    , fn = fn\n",
    "    , decimals = 4\n",
    ")\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall_sensitivity}')\n",
    "print(f'F1: {fscore}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Balanced Accuracy: {balanced_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
